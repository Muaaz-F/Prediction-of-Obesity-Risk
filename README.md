# Obesity Classification Project

This project aims to classify individuals into different obesity levels based on various features such as age, gender, height, weight, and lifestyle factors. The classification is performed using machine learning algorithms, particularly Gradient Boosting, after thorough data preprocessing and hyperparameter optimization.

## Table of Contents

1. [Introduction](#introduction)
2. [Dataset](#dataset)
3. [Project Structure](#project-structure)
4. [Usage](#usage)
5. [Results](#results)
6. [Contributing](#contributing)
7. [License](#license)

## Introduction

Obesity is a significant health concern globally, and its classification is crucial for personalized healthcare interventions. This project utilizes machine learning techniques to classify individuals into different obesity levels, aiding in early intervention and personalized treatment plans.

## Dataset

The dataset used in this project contains anonymized features such as age, gender, height, weight, and lifestyle factors (e.g., diet, physical activity) of individuals. Additionally, it includes the target variable indicating the obesity level.

## Project Structure

## Overview:

### Definition of the Task:
The task in this project is to classify individuals into different obesity levels based on various features such as age, gender, and lifestyle habits. The dataset includes anonymized information about individuals along with their corresponding obesity level.

### Your Approach:
Our approach formulates the problem as a classification task, where the goal is to predict the obesity level of individuals based on their features. We experimented with various machine learning algorithms such as Gradient Boosting and Voting Classifier. Additionally, feature selection techniques and ensemble modeling were employed to enhance the predictive performance.

### Summary of Performance Achieved:
Our best model achieved an accuracy of 90.39% on the validation set. This means that the model accurately predicted the obesity level of individuals in the test data 90.39% of the time. As of the latest evaluation, the best performance on Kaggle for this task is 91.5%, indicating that our model is competitive with the top-performing solutions on the platform.

